reading comprehension model by transformer
- The Architecture of this model employed the **transformer feature** parallized attention + **BiDAF query-wise Passage content state** + **PointerNetwork**. 


- train Loss:![loss](https://github.com/fooSynaptic/transfromer_NN_Block/blob/master/images/rc_model_train_loss.png)
